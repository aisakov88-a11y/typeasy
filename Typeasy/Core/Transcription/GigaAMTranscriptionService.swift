import Foundation
import SherpaOnnx

/// Service for speech-to-text transcription using GigaAM-v3 E2E RNN-T via sherpa-onnx
/// GigaAM-v3 RNN-T with automatic punctuation - optimized for Russian with 50% better accuracy than Whisper
/// Produces punctuated, normalized text directly without requiring LLM post-processing
@MainActor
final class GigaAMTranscriptionService: ObservableObject, TranscriptionServiceProtocol {
    // MARK: - Published Properties

    @Published var isModelLoaded = false
    @Published var downloadProgress: Double = 0.0
    @Published var downloadStatus: String = ""

    // MARK: - Private Properties

    private var recognizer: OpaquePointer? // sherpa-onnx C API pointer (will be implemented after framework builds)
    private let modelCacheDir: URL

    // MARK: - Model Configuration

    private let modelName = "sherpa-onnx-nemo-transducer-punct-giga-am-v3-russian-2025-12-16"
    private let huggingFaceRepo = "csukuangfj/sherpa-onnx-nemo-transducer-punct-giga-am-v3-russian-2025-12-16"

    // MARK: - Initialization

    init() {
        // Setup model cache directory
        let homeDir = FileManager.default.homeDirectoryForCurrentUser
        modelCacheDir = homeDir
            .appendingPathComponent("Library")
            .appendingPathComponent("Caches")
            .appendingPathComponent("typeasy")
            .appendingPathComponent("gigaam")

        NSLog("ðŸŽ¤ GigaAMTranscriptionService initialized with cache dir: \(modelCacheDir.path)")
    }

    // MARK: - TranscriptionServiceProtocol Implementation

    /// Initialize the GigaAM model
    /// Downloads the model if not already cached
    func initialize() async throws {
        print("ðŸ”„ GigaAMTranscriptionService.initialize() called")
        NSLog("ðŸ”„ GigaAMTranscriptionService.initialize() called")
        downloadStatus = "Checking for model..."

        // 1. Check if model exists locally
        let modelPath = modelCacheDir.appendingPathComponent(modelName)
        print("ðŸ“‚ Checking model path: \(modelPath.path)")
        NSLog("ðŸ“‚ Checking model path: \(modelPath.path)")

        let modelExists = FileManager.default.fileExists(atPath: modelPath.path)
        print("ðŸ“‚ Model exists: \(modelExists)")
        NSLog("ðŸ“‚ Model exists: \(modelExists)")

        if !modelExists {
            // 2. Download model automatically
            NSLog("ðŸ“¥ Model not found, starting download...")
            downloadStatus = "Downloading GigaAM-v3 RNN-T with punctuation..."
            try await downloadModel()
            NSLog("âœ… Download completed!")
        } else {
            NSLog("âœ… Model found in cache: \(modelPath.path)")
        }

        // 3. Load model using sherpa-onnx C API
        NSLog("ðŸ“¦ Loading model...")
        downloadStatus = "Loading model with punctuation..."
        try loadModel(from: modelPath)

        isModelLoaded = true
        downloadProgress = 1.0
        downloadStatus = "GigaAM-v3 with punctuation loaded successfully"
        NSLog("âœ… GigaAM-v3 RNN-T with punctuation loaded successfully")
    }

    /// Download GigaAM-v3 model from HuggingFace
    private func downloadModel() async throws {
        NSLog("ðŸš€ downloadModel() started")
        let repoURL = "https://huggingface.co/\(huggingFaceRepo)/resolve/main"
        NSLog("ðŸ“ Repo URL: \(repoURL)")

        let files = [
            "encoder.int8.onnx",    // Encoder (quantized) - 214MB
            "decoder.onnx",         // Decoder - 4.4MB
            "joiner.onnx",          // Joiner - 2.6MB
            "tokens.txt",           // Vocabulary tokens (1025 tokens) - 13KB
            "README.md"             // Documentation - 302B
        ]
        NSLog("ðŸ“‹ Files to download: \(files.count)")

        // Create model directory
        let modelPath = modelCacheDir.appendingPathComponent(modelName)
        NSLog("ðŸ“‚ Creating directory: \(modelPath.path)")
        try FileManager.default.createDirectory(
            at: modelPath,
            withIntermediateDirectories: true
        )

        NSLog("ðŸ“‚ Created model directory: \(modelPath.path)")

        // Configure URLSession with timeout and redirect handling
        let config = URLSessionConfiguration.default
        config.timeoutIntervalForRequest = 300  // 5 minutes for large files
        config.timeoutIntervalForResource = 3600  // 1 hour total
        config.httpMaximumConnectionsPerHost = 1
        let session = URLSession(configuration: config)

        // Download each file with progress tracking
        for (index, file) in files.enumerated() {
            let fileURL = URL(string: "\(repoURL)/\(file)")!
            let destination = modelPath.appendingPathComponent(file)

            // Skip if file already exists
            if FileManager.default.fileExists(atPath: destination.path) {
                NSLog("â­ï¸ Skipping \(file) (already exists)")
                continue
            }

            NSLog("ðŸ“¥ Downloading \(file) from \(fileURL)...")
            downloadStatus = "Downloading \(file)..."

            do {
                // Create request with proper headers
                var request = URLRequest(url: fileURL)
                request.setValue("Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36", forHTTPHeaderField: "User-Agent")
                request.setValue("*/*", forHTTPHeaderField: "Accept")
                request.httpMethod = "GET"

                // Use data(for:) instead of bytes(for:) - much faster for large files
                let (data, response) = try await session.data(for: request)

                guard let httpResponse = response as? HTTPURLResponse else {
                    throw PipelineError.modelNotLoaded
                }

                guard (200...299).contains(httpResponse.statusCode) else {
                    NSLog("âŒ HTTP \(httpResponse.statusCode) for \(file)")
                    throw PipelineError.modelNotLoaded
                }

                // Write to destination
                try data.write(to: destination)
                NSLog("âœ… Downloaded \(file) (\(data.count) bytes)")

                // Update progress
                let overallProgress = Double(index + 1) / Double(files.count)
                await MainActor.run {
                    self.downloadProgress = overallProgress
                    self.downloadStatus = "Downloaded \(file) (\(data.count / 1_000_000)MB)"
                }

            } catch {
                NSLog("âŒ Failed to download \(file): \(error)")
                throw PipelineError.modelNotLoaded
            }
        }

        session.invalidateAndCancel()
        NSLog("âœ… All model files downloaded successfully")
    }

    /// Load GigaAM-v3 RNN-T model with punctuation using sherpa-onnx C API
    private func loadModel(from path: URL) throws {
        NSLog("ðŸ”„ Loading GigaAM-v3 RNN-T model with punctuation from: \(path.path)")

        // Prepare file paths for transducer model (encoder, decoder, joiner)
        let encoderPath = path.appendingPathComponent("encoder.int8.onnx").path
        let decoderPath = path.appendingPathComponent("decoder.onnx").path
        let joinerPath = path.appendingPathComponent("joiner.onnx").path
        let tokensPath = path.appendingPathComponent("tokens.txt").path

        // Verify all files exist
        guard FileManager.default.fileExists(atPath: encoderPath) else {
            NSLog("âŒ Encoder file not found: \(encoderPath)")
            throw PipelineError.modelNotLoaded
        }
        guard FileManager.default.fileExists(atPath: decoderPath) else {
            NSLog("âŒ Decoder file not found: \(decoderPath)")
            throw PipelineError.modelNotLoaded
        }
        guard FileManager.default.fileExists(atPath: joinerPath) else {
            NSLog("âŒ Joiner file not found: \(joinerPath)")
            throw PipelineError.modelNotLoaded
        }
        guard FileManager.default.fileExists(atPath: tokensPath) else {
            NSLog("âŒ Tokens file not found: \(tokensPath)")
            throw PipelineError.modelNotLoaded
        }

        NSLog("ðŸ“‚ Encoder: \(encoderPath)")
        NSLog("ðŸ“‚ Decoder: \(decoderPath)")
        NSLog("ðŸ“‚ Joiner: \(joinerPath)")
        NSLog("ðŸ“‚ Tokens: \(tokensPath)")

        // Create recognizer configuration
        var config = SherpaOnnxOfflineRecognizerConfig()

        // Configure feature extraction
        config.feat_config.sample_rate = 16000  // Must match AudioCaptureManager
        config.feat_config.feature_dim = 80     // Standard for speech models

        // Configure NeMo Transducer model (GigaAM-v3 RNN-T with punctuation)
        // Use strdup and convert to UnsafePointer (immutable)
        let encoderPathCStr = strdup(encoderPath)
        let decoderPathCStr = strdup(decoderPath)
        let joinerPathCStr = strdup(joinerPath)
        let tokensPathCStr = strdup(tokensPath)
        let providerCStr = strdup("cpu")
        let modelTypeCStr = strdup("")
        let decodingMethodCStr = strdup("greedy_search")

        config.model_config.transducer.encoder = UnsafePointer(encoderPathCStr)
        config.model_config.transducer.decoder = UnsafePointer(decoderPathCStr)
        config.model_config.transducer.joiner = UnsafePointer(joinerPathCStr)
        config.model_config.tokens = UnsafePointer(tokensPathCStr)
        config.model_config.num_threads = 4     // Use multiple CPU cores
        config.model_config.debug = 0           // Disable debug output
        config.model_config.provider = UnsafePointer(providerCStr)
        config.model_config.model_type = UnsafePointer(modelTypeCStr)

        // Configure decoding for RNN-T
        config.decoding_method = UnsafePointer(decodingMethodCStr)
        config.max_active_paths = 4

        // Create recognizer
        NSLog("ðŸ”§ Creating sherpa-onnx offline transducer recognizer with punctuation...")
        recognizer = SherpaOnnxCreateOfflineRecognizer(&config)

        // Free string duplicates (config is copied internally by sherpa-onnx)
        free(encoderPathCStr)
        free(decoderPathCStr)
        free(joinerPathCStr)
        free(tokensPathCStr)
        free(providerCStr)
        free(modelTypeCStr)
        free(decodingMethodCStr)

        guard recognizer != nil else {
            NSLog("âŒ Failed to create transducer recognizer - SherpaOnnxCreateOfflineRecognizer returned nil")
            throw PipelineError.modelNotLoaded
        }

        NSLog("âœ… GigaAM-v3 RNN-T recognizer with punctuation created successfully")
    }

    /// Transcribe audio samples to Russian text
    /// - Parameters:
    ///   - audioSamples: Audio data as Float32 array (16kHz mono)
    ///   - language: Ignored - GigaAM only supports Russian
    ///   - contextPrompt: Ignored - GigaAM doesn't support context prompts
    /// - Returns: Transcription result
    func transcribe(audioSamples: [Float], language: String?, contextPrompt: String?) async throws -> TranscriptionResultData {
        guard let recognizer = recognizer else {
            NSLog("âŒ GigaAM recognizer not initialized")
            throw PipelineError.modelNotLoaded
        }

        guard !audioSamples.isEmpty else {
            NSLog("âš ï¸ Empty audio samples")
            return TranscriptionResultData(text: "", language: "ru", segments: [])
        }

        NSLog("ðŸŽ¤ Starting GigaAM transcription with \(audioSamples.count) samples")

        // Run transcription on background thread to avoid blocking main thread
        return try await Task.detached {
            // Create offline stream
            guard let stream = SherpaOnnxCreateOfflineStream(recognizer) else {
                NSLog("âŒ Failed to create offline stream")
                throw PipelineError.transcriptionFailed("Failed to create stream")
            }
            defer {
                // Always cleanup stream
                SherpaOnnxDestroyOfflineStream(stream)
            }

            // Feed audio samples to stream
            // Note: sherpa-onnx expects samples in range [-1, 1]
            audioSamples.withUnsafeBufferPointer { buffer in
                guard let baseAddress = buffer.baseAddress else { return }
                SherpaOnnxAcceptWaveformOffline(
                    stream,
                    16000,  // Sample rate (must match feat_config)
                    baseAddress,
                    Int32(buffer.count)
                )
            }

            // Run decoding
            NSLog("ðŸ” Decoding audio with GigaAM-v3...")
            SherpaOnnxDecodeOfflineStream(recognizer, stream)

            // Get result
            guard let result = SherpaOnnxGetOfflineStreamResult(stream) else {
                NSLog("âŒ Failed to get transcription result")
                throw PipelineError.transcriptionFailed("Failed to get result")
            }
            defer {
                // Cleanup result
                SherpaOnnxDestroyOfflineRecognizerResult(result)
            }

            // Extract text from result
            let text: String
            if let textPtr = result.pointee.text {
                text = String(cString: textPtr)
            } else {
                text = ""
            }

            NSLog("âœ… GigaAM transcription completed: '\(text)'")

            // Extract timestamps if available
            let segments: [TranscriptionSegmentData] = []
            if result.pointee.timestamps != nil && result.pointee.count > 0 {
                // GigaAM provides timestamps per token
                // For now, we skip segment extraction as it requires token-level processing
                NSLog("ðŸ“Š Timestamps available: \(result.pointee.count) tokens")
            }

            return TranscriptionResultData(
                text: text,
                language: "ru",  // GigaAM only supports Russian
                segments: segments
            )
        }.value
    }

    // MARK: - Cleanup

    deinit {
        // Cleanup sherpa-onnx resources
        if let recognizer = recognizer {
            SherpaOnnxDestroyOfflineRecognizer(recognizer)
            NSLog("ðŸ§¹ GigaAM recognizer destroyed")
        }
    }
}
