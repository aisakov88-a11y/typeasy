import SwiftUI
import Combine
import HotKey

/// Main orchestrator for the dictation flow
@MainActor
final class DictationPipeline: ObservableObject {
    // MARK: - Published State

    @Published private(set) var state: PipelineState = .idle
    @Published private(set) var lastTranscription: String = ""
    @Published private(set) var lastProcessedText: String = ""
    @Published private(set) var whisperModelLoaded: Bool = false
    @Published private(set) var llmModelLoaded: Bool = false

    // MARK: - Services

    private let audioCaptureManager = AudioCaptureManager()

    // Dual transcription services
    private let gigaAMService = GigaAMTranscriptionService()
    private let whisperKitService = WhisperKitTranscriptionService()

    private let llmService = LLMService()
    private let textInsertionService = TextInsertionService()

    // Current active service
    private var activeTranscriptionService: any TranscriptionServiceProtocol
    private var selectedSTTEngine: STTEngine = .gigaAM

    // MARK: - Hotkey

    private var hotKey: HotKey?

    // MARK: - Settings

    private var enableLLMProcessing: Bool = false
    private var llmPrompt: String = DefaultPrompts.cleanup
    private var selectedLanguage: Language = .russian
    private var textReplacements: [TextReplacement] = []
    private var whisperContextPrompt: String = DefaultPrompts.whisperContext

    // MARK: - Initialization

    init() {
        // Default to GigaAM service with punctuation
        activeTranscriptionService = gigaAMService

        NSLog("ğŸš€ DictationPipeline init() called")
        writeLog("ğŸš€ DictationPipeline init() called")

        state = .initializing
        setupHotkey()

        // Auto-initialize models on creation
        Task { @MainActor in
            NSLog("ğŸ“¦ Starting model initialization task...")
            writeLog("ğŸ“¦ Starting model initialization task...")
            do {
                try await self.initializeModels()
            } catch {
                NSLog("âŒ Failed to initialize models in init: \(error)")
                writeLog("âŒ Failed to initialize models in init: \(error)")
            }
        }
    }

    private func writeLog(_ message: String) {
        let logFile = "/tmp/typeasy_debug.log"
        let timestamp = Date().formatted()
        let logMessage = "[\(timestamp)] \(message)\n"
        if let data = logMessage.data(using: .utf8) {
            if FileManager.default.fileExists(atPath: logFile) {
                if let fileHandle = FileHandle(forWritingAtPath: logFile) {
                    fileHandle.seekToEndOfFile()
                    fileHandle.write(data)
                    fileHandle.closeFile()
                }
            } else {
                try? data.write(to: URL(fileURLWithPath: logFile))
            }
        }
    }

    private func setupHotkey() {
        // Cmd+Shift+D
        hotKey = HotKey(key: .d, modifiers: [.command, .shift])
        hotKey?.keyDownHandler = { [weak self] in
            Task { @MainActor in
                await self?.toggleRecording()
            }
        }
    }

    // MARK: - Public Methods

    /// Toggle recording state
    func toggleRecording() async {
        switch state {
        case .idle:
            await startRecording()
        case .recording:
            await stopAndProcess()
        default:
            // Ignore during processing
            break
        }
    }

    /// Initialize all models
    func initializeModels() async throws {
        NSLog("ğŸ”„ Starting model initialization...")
        writeLog("ğŸ”„ Starting model initialization...")
        state = .initializing
        whisperModelLoaded = false
        llmModelLoaded = false

        do {
            NSLog("ğŸ“ Initializing Speech Recognition (\(selectedSTTEngine.displayName))...")
            writeLog("ğŸ“ Initializing Speech Recognition (\(selectedSTTEngine.displayName))...")

            // Initialize active STT engine
            NSLog("ğŸ”€ Switching on STT engine: \(selectedSTTEngine.rawValue)")
            writeLog("ğŸ”€ Switching on STT engine: \(selectedSTTEngine.rawValue)")
            switch selectedSTTEngine {
            case .gigaAM:
                NSLog("ğŸ“¥ Calling gigaAMService.initialize()...")
                writeLog("ğŸ“¥ Calling gigaAMService.initialize()...")
                try await gigaAMService.initialize()
                NSLog("ğŸ“¥ gigaAMService.initialize() completed")
                writeLog("ğŸ“¥ gigaAMService.initialize() completed")
                whisperModelLoaded = gigaAMService.isModelLoaded
            case .whisperKit:
                NSLog("ğŸ“¥ Calling whisperKitService.initialize()...")
                writeLog("ğŸ“¥ Calling whisperKitService.initialize()...")
                try await whisperKitService.initialize()
                NSLog("ğŸ“¥ whisperKitService.initialize() completed")
                writeLog("ğŸ“¥ whisperKitService.initialize() completed")
                whisperModelLoaded = whisperKitService.isModelLoaded
            }

            NSLog("âœ… Speech Recognition initialized, loaded: \(whisperModelLoaded)")
            writeLog("âœ… Speech Recognition initialized, loaded: \(whisperModelLoaded)")

            NSLog("ğŸ¤– Initializing LLM service...")
            writeLog("ğŸ¤– Initializing LLM service...")
            try await llmService.initialize()
            llmModelLoaded = llmService.isModelLoaded
            NSLog("âœ… LLM service initialized, loaded: \(llmModelLoaded)")
            writeLog("âœ… LLM service initialized, loaded: \(llmModelLoaded)")

            state = .idle
            NSLog("âœ… All models initialized successfully")
            writeLog("âœ… All models initialized successfully")
        } catch {
            NSLog("âŒ Model initialization failed: \(error.localizedDescription)")
            writeLog("âŒ Model initialization failed: \(error.localizedDescription)")
            state = .error(.modelNotLoaded)
            throw error
        }
    }

    /// Update settings from AppState
    func updateSettings(
        enableLLM: Bool,
        prompt: String,
        language: Language? = nil,
        replacements: [TextReplacement]? = nil,
        whisperModel: WhisperModel? = nil,
        sttEngine: STTEngine? = nil
    ) {
        NSLog("âš™ï¸ Updating settings: enableLLM=\(enableLLM), language=\(language?.rawValue ?? "unchanged")")
        writeLog("âš™ï¸ Updating settings: enableLLM=\(enableLLM), prompt length=\(prompt.count)")
        self.enableLLMProcessing = enableLLM
        self.llmPrompt = prompt
        if let language = language {
            self.selectedLanguage = language
        }
        if let replacements = replacements {
            self.textReplacements = replacements
            NSLog("âš™ï¸ Updated text replacements: \(replacements.count) rules")
            writeLog("âš™ï¸ Updated text replacements: \(replacements.count) rules")
        }

        // Handle STT engine switch
        if let engine = sttEngine, engine != selectedSTTEngine {
            NSLog("âš™ï¸ STT engine change requested: \(engine.displayName)")
            writeLog("âš™ï¸ STT engine change requested: \(engine.displayName)")
            Task {
                await switchSTTEngine(engine)
            }
        }

        // Handle WhisperKit model change (only if WhisperKit is active)
        if let model = whisperModel, selectedSTTEngine == .whisperKit {
            NSLog("âš™ï¸ Model change requested: \(model.displayName)")
            writeLog("âš™ï¸ Model change requested: \(model.displayName)")
            Task {
                await changeWhisperModel(model)
            }
        }
    }

    /// Change Whisper model
    func changeWhisperModel(_ model: WhisperModel) async {
        NSLog("ğŸ”„ Changing Whisper model to: \(model.fullModelName)")
        writeLog("ğŸ”„ Changing Whisper model to: \(model.fullModelName)")
        state = .initializing
        whisperModelLoaded = false

        do {
            try await whisperKitService.initialize(modelName: model.fullModelName)
            whisperModelLoaded = whisperKitService.isModelLoaded
            state = .idle
            NSLog("âœ… Model changed successfully to \(model.displayName)")
            writeLog("âœ… Model changed successfully to \(model.displayName)")
        } catch {
            NSLog("âŒ Failed to change model: \(error)")
            writeLog("âŒ Failed to change model: \(error)")
            state = .error(.modelNotLoaded)
        }
    }

    /// Switch STT engine (GigaAM â†” WhisperKit)
    private func switchSTTEngine(_ engine: STTEngine) async {
        NSLog("ğŸ”„ Switching STT engine to: \(engine.displayName)")
        writeLog("ğŸ”„ Switching STT engine to: \(engine.displayName)")
        state = .initializing
        selectedSTTEngine = engine
        whisperModelLoaded = false

        do {
            switch engine {
            case .gigaAM:
                activeTranscriptionService = gigaAMService
                try await gigaAMService.initialize()
                whisperModelLoaded = gigaAMService.isModelLoaded
            case .whisperKit:
                activeTranscriptionService = whisperKitService
                try await whisperKitService.initialize()
                whisperModelLoaded = whisperKitService.isModelLoaded
            }

            state = .idle
            NSLog("âœ… STT engine switched successfully to \(engine.displayName)")
            writeLog("âœ… STT engine switched successfully")
        } catch {
            NSLog("âŒ Failed to switch STT engine: \(error)")
            writeLog("âŒ Failed to switch STT engine: \(error)")
            state = .error(.modelNotLoaded)
        }
    }

    /// Update hotkey
    func updateHotkey(key: Key, modifiers: NSEvent.ModifierFlags) {
        hotKey = HotKey(key: key, modifiers: modifiers)
        hotKey?.keyDownHandler = { [weak self] in
            Task { @MainActor in
                await self?.toggleRecording()
            }
        }
    }

    // MARK: - Private Methods

    private func startRecording() async {
        NSLog("ğŸ¤ Starting recording...")
        writeLog("ğŸ¤ Starting recording...")
        do {
            state = .recording
            try await audioCaptureManager.startCapture()
            NSLog("âœ… Recording started successfully")
            writeLog("âœ… Recording started successfully")
        } catch {
            NSLog("âŒ Recording failed: \(error)")
            writeLog("âŒ Recording failed: \(error)")
            state = .error(.audioCaptureFailed(error.localizedDescription))
        }
    }

    private func stopAndProcess() async {
        NSLog("â¹ï¸ Stopping recording and processing...")
        writeLog("â¹ï¸ Stopping recording and processing...")

        // Stop recording and get audio samples
        let audioSamples = audioCaptureManager.stopCapture()
        NSLog("ğŸ“Š Captured \(audioSamples.count) audio samples")
        writeLog("ğŸ“Š Captured \(audioSamples.count) audio samples")

        guard !audioSamples.isEmpty else {
            NSLog("âš ï¸ No audio samples captured")
            writeLog("âš ï¸ No audio samples captured")
            state = .idle
            return
        }

        // Transcribe
        state = .transcribing
        NSLog("ğŸ“ Starting transcription with language: \(selectedLanguage.rawValue) using \(selectedSTTEngine.displayName)")
        writeLog("ğŸ“ Starting transcription with language: \(selectedLanguage.rawValue)")
        do {
            // Convert Language enum to language code (ru/en/nil for auto)
            let languageCode = selectedLanguage == .auto ? nil : selectedLanguage.rawValue
            // Pass context prompt for WhisperKit (GigaAM ignores it)
            let transcription = try await activeTranscriptionService.transcribe(
                audioSamples: audioSamples,
                language: languageCode,
                contextPrompt: whisperContextPrompt
            )
            lastTranscription = transcription.text
            NSLog("âœ… Transcription: '\(transcription.text)'")
            writeLog("âœ… Transcription: '\(transcription.text)'")

            guard !transcription.text.isEmpty else {
                NSLog("âš ï¸ Empty transcription")
                writeLog("âš ï¸ Empty transcription")
                state = .idle
                return
            }

            var finalText = transcription.text

            // LLM processing (if enabled)
            NSLog("ğŸ¤– LLM processing enabled: \(enableLLMProcessing)")
            writeLog("ğŸ¤– LLM processing enabled: \(enableLLMProcessing)")
            if enableLLMProcessing {
                state = .processing
                NSLog("ğŸ§¹ Starting LLM cleanup...")
                writeLog("ğŸ§¹ Starting LLM cleanup with prompt length: \(llmPrompt.count)")
                do {
                    let processedText = try await llmService.cleanupText(
                        transcription.text,
                        prompt: llmPrompt
                    )
                    finalText = processedText
                    lastProcessedText = processedText
                    NSLog("âœ… LLM processed text: '\(processedText)'")
                    writeLog("âœ… LLM processed text: '\(processedText)'")
                } catch {
                    // Fall back to raw transcription if LLM fails
                    NSLog("âŒ LLM processing failed: \(error), using raw transcription")
                    writeLog("âŒ LLM processing failed: \(error), using raw transcription")
                    finalText = transcription.text
                    lastProcessedText = transcription.text
                }
            } else {
                NSLog("â­ï¸ Skipping LLM processing (disabled)")
                writeLog("â­ï¸ Skipping LLM processing (disabled)")
                finalText = transcription.text
                lastProcessedText = transcription.text
            }

            // Apply custom text replacements AFTER LLM processing
            if !textReplacements.isEmpty {
                NSLog("ğŸ”„ Applying \(textReplacements.count) text replacements...")
                writeLog("ğŸ”„ Text before replacements: '\(finalText)'")
                let beforeReplacements = finalText
                var replacementsApplied = 0

                for replacement in textReplacements {
                    let result = replacement.apply(to: finalText)
                    if result != finalText {
                        replacementsApplied += 1
                        NSLog("  âœ“ Replaced '\(replacement.trigger)' â†’ '\(replacement.replacement)'")
                    }
                    finalText = result
                }

                if replacementsApplied > 0 {
                    NSLog("âœ… Applied \(replacementsApplied)/\(textReplacements.count) replacements")
                    writeLog("âœ… Text after replacements: '\(finalText)'")
                } else {
                    NSLog("â„¹ï¸ No replacement triggers found in text")
                }
            }

            // Insert text
            state = .inserting
            NSLog("ğŸ“‹ Inserting text: '\(finalText)'")
            writeLog("ğŸ“‹ Inserting text: '\(finalText)'")
            try textInsertionService.insertText(finalText)
            NSLog("âœ… Text inserted successfully")
            writeLog("âœ… Text inserted successfully")

            state = .idle

        } catch let error as PipelineError {
            NSLog("âŒ Pipeline error: \(error)")
            writeLog("âŒ Pipeline error: \(error)")
            state = .error(error)
        } catch {
            NSLog("âŒ Transcription error: \(error)")
            writeLog("âŒ Transcription error: \(error)")
            state = .error(.transcriptionFailed(error.localizedDescription))
        }
    }
}
